{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6638,
     "status": "ok",
     "timestamp": 1770321834001,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "dA2WtJrxNI7R",
    "outputId": "0614f29f-f1b3-4268-d6f7-cea585ea2dec"
   },
   "outputs": [],
   "source": [
    "# pip install faiss-gpu-cu12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4578,
     "status": "ok",
     "timestamp": 1770321838593,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "qCzoOzuCNJn8",
    "outputId": "c90124e5-b8c0-4eb3-a267-9adf0ff72a82"
   },
   "outputs": [],
   "source": [
    "# pip install langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16475,
     "status": "ok",
     "timestamp": 1770321855069,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "XIDosRe-NOCL",
    "outputId": "da426736-2d7d-45c9-c592-c2a1dcc1c7ad"
   },
   "outputs": [],
   "source": [
    "# pip install langchain-huggingface sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9353,
     "status": "ok",
     "timestamp": 1770321864423,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "Vm52otLQNp6w",
    "outputId": "3e907d49-4706-40db-d2d6-834570691061"
   },
   "outputs": [],
   "source": [
    "# pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4644,
     "status": "ok",
     "timestamp": 1770321869069,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "RRGiS1sVNOJF",
    "outputId": "0f81e53f-4b01-4d7a-a767-843a5d9ee64f"
   },
   "outputs": [],
   "source": [
    "# pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4778,
     "status": "ok",
     "timestamp": 1770321873848,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "mfj35bz6XFah",
    "outputId": "982b7359-9969-4f89-b514-b272eded974c"
   },
   "outputs": [],
   "source": [
    "# pip install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1770321873904,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "IX9rn8gcNXxL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 25188,
     "status": "ok",
     "timestamp": 1770321899093,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "GBFYOC-GNX0Y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional, Dict\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    TextLoader,\n",
    "    JSONLoader\n",
    ")\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2549,
     "status": "ok",
     "timestamp": 1770321912827,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "nrnn_bzQ5DUs",
    "outputId": "1a6ffc30-6c9d-405c-cd7e-f056e01d5396"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1770321912844,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "NoIT4WGKz1NA"
   },
   "outputs": [],
   "source": [
    "# main_path = '/content/drive/MyDrive/PRACTICUM_DLE/sprint_7/'\n",
    "main_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0_3463K4eTf"
   },
   "source": [
    "# 1 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1770321915941,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "l5K5Uoc64hoH"
   },
   "outputs": [],
   "source": [
    "data_path = main_path + 'nlp_s3_project/'\n",
    "\n",
    "data_json_path = data_path + 'arxiv-metadata-s.json'\n",
    "data_csv_path = data_path + 'test_sample.csv'\n",
    "\n",
    "data_sample_path = data_path + 'sample_data.json'\n",
    "data_sample2_path = data_path + 'sample_data2.json'\n",
    "data_sample3_path = data_path + 'sample_data3.json'\n",
    "data_sample4_path = data_path + 'sample_data4.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path + 'sample_data.json', 'w') as file:\n",
    "#   json.dump(train_data[:10000], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 8578,
     "status": "ok",
     "timestamp": 1770321925691,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "d6qe4U1h0j_A"
   },
   "outputs": [],
   "source": [
    "with open(data_json_path, 'r') as file:\n",
    "  train_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1770321926595,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "X3zhk7Z7X3Yl"
   },
   "outputs": [],
   "source": [
    "with open(data_sample_path, 'r') as file:\n",
    "  sample_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_sample2_path, 'r') as file:\n",
    "  sample_data2 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_sample3_path, 'r') as file:\n",
    "  sample_data3 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_sample4_path, 'r') as file:\n",
    "  sample_data4 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1770321936957,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "6foFcmfgaN5x",
    "outputId": "3dd4c2dd-c42e-4a5f-f644-9b17bfca38ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 505, 100, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_data), len(sample_data2), len(sample_data3), len(sample_data4), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 429,
     "status": "ok",
     "timestamp": 1770321927026,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "5jGPAH4vVhc1"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(data_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_test[:100]['id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our_ids = []\n",
    "# for i, elem in tqdm(enumerate(train_data)):\n",
    "#     if elem['id'] in df_test[:100]['id'].tolist():\n",
    "#         # print(i)\n",
    "#         our_ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our_ids = []\n",
    "# for j, row in tqdm(df_test[:100].iterrows()):\n",
    "#     for i, elem in (enumerate(train_data)):\n",
    "#         if elem['id'] == row['id']:\n",
    "#             our_ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_data4 = [train_data[i] for i in our_ids] #+ random.sample(train_data, 100)\n",
    "# len(sample_data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_data4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path + 'sample_data4.json', 'w') as file:\n",
    "#   json.dump(sample_data4, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1770321927049,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "8INRHTsQCPuX"
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(random.sample(train_data, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1770321927140,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "usD-1ZVoCTht",
    "outputId": "00765c0a-11f5-4c62-cbbf-3e817190a2e2"
   },
   "outputs": [],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qv9vpagRGgq6"
   },
   "source": [
    "## title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82145,
     "status": "aborted",
     "timestamp": 1770321909193,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "eEZ7ZwATGbu9"
   },
   "outputs": [],
   "source": [
    "df_train['title'].apply(lambda x: len(x.split())).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['title'].str.len().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82144,
     "status": "aborted",
     "timestamp": 1770321909193,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "txtdL29WG833"
   },
   "outputs": [],
   "source": [
    "df_train['abstract'].apply(lambda x: len(x.split())).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['abstract'].str.len().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_name = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "emb_tokenizer = AutoTokenizer.from_pretrained(embedder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rezu = emb_tokenizer(df_train['abstract'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rezu.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(tk) for tk in rezu['input_ids']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(tk) for tk in rezu['input_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzNIegDkGcwi"
   },
   "source": [
    "## submitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82142,
     "status": "aborted",
     "timestamp": 1770321909194,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "GFI5nUJYCfMX"
   },
   "outputs": [],
   "source": [
    "df_train['submitter'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJP8fap1DbDb"
   },
   "source": [
    "## tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82143,
     "status": "aborted",
     "timestamp": 1770321909199,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "YZItX6BeDZDl"
   },
   "outputs": [],
   "source": [
    "categories_dict = {}\n",
    "for cats in df_train['categories']:\n",
    "  for cat in cats.split():\n",
    "    if cat in categories_dict:\n",
    "      categories_dict[cat] += 1\n",
    "    else:\n",
    "      categories_dict[cat] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82142,
     "status": "aborted",
     "timestamp": 1770321909199,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "RNMbH7EMD-co"
   },
   "outputs": [],
   "source": [
    "df_cats = pd.DataFrame([[k, v] for k, v in categories_dict.items()], columns=['category', 'count']).sort_values('count', ascending=False).reset_index(drop=True)\n",
    "df_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82141,
     "status": "aborted",
     "timestamp": 1770321909200,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "p5vFvcBJF0On"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82141,
     "status": "aborted",
     "timestamp": 1770321909201,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "pQ9EhxV4F0Ry"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82139,
     "status": "aborted",
     "timestamp": 1770321909201,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "mOVtmeZ4FJ3t"
   },
   "outputs": [],
   "source": [
    "df_train['categories'].apply(lambda x: len(x.split())).value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2OfTqfOFxOu"
   },
   "source": [
    "## update_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82139,
     "status": "aborted",
     "timestamp": 1770321909202,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "23KNAPxuFJ6d"
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(df_train['update_date']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82138,
     "status": "aborted",
     "timestamp": 1770321909202,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "TCnPfXymFu7y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53dzcwpOFvty"
   },
   "source": [
    "## versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82137,
     "status": "aborted",
     "timestamp": 1770321909203,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "wGtMfS3aFgc_"
   },
   "outputs": [],
   "source": [
    "df_train['versions'].apply(lambda x: len(x)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0dokDwRGHXf"
   },
   "source": [
    "## authors_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82136,
     "status": "aborted",
     "timestamp": 1770321909203,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "ZVqA4IXHGLTn"
   },
   "outputs": [],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82135,
     "status": "aborted",
     "timestamp": 1770321909204,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "OeIvFDsYCxv-"
   },
   "outputs": [],
   "source": [
    "df_train['authors_parsed'].apply(lambda x: len(x)).value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82134,
     "status": "aborted",
     "timestamp": 1770321909204,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "JngWUWEWGTwl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npQCUHtCHKYs"
   },
   "source": [
    "## 1.2 Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82148,
     "status": "aborted",
     "timestamp": 1770321909221,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "d6-H6VKu0kCE"
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82148,
     "status": "aborted",
     "timestamp": 1770321909222,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "HnhBXz_ZHbj2"
   },
   "outputs": [],
   "source": [
    "df_test.loc[0, 'query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82157,
     "status": "aborted",
     "timestamp": 1770321909232,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "w7c9XdxKHcIm"
   },
   "outputs": [],
   "source": [
    "df_test.loc[0, 'abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82167,
     "status": "aborted",
     "timestamp": 1770321909243,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "wE5ybziwHOlp"
   },
   "outputs": [],
   "source": [
    "df_test['abstract'].apply(lambda x: len(x.split())).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82166,
     "status": "aborted",
     "timestamp": 1770321909244,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "EHBy5A6-HWnM"
   },
   "outputs": [],
   "source": [
    "df_test['query'].apply(lambda x: len(x.split())).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTvwilEgHpvK"
   },
   "source": [
    "# Выводы по EDA\n",
    "\n",
    "1. как вы будете решать задачу;\n",
    "- Сделаем RAG+LLM\n",
    "2. какие подходы к поиску примените и почему;\n",
    "- Графовая БД index какой-то\n",
    "3. какие модели выберете и от каких ограничений будете отталкиваться;\n",
    "- Как в примерах\n",
    "4. из чего будет состоять ваша система.\n",
    "- Загрузчик данных\n",
    "- Ембеддер данных\n",
    "- БДшка векторная и индекс\n",
    "- функция поиска релевантных данных к запросу\n",
    "- функция ранжирования релеввантных\n",
    "- Формирование комби запроса с учетом релевантных\n",
    "- Инференс с ЛЛМ\n",
    "- расчет метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbuvhN7WIyH9"
   },
   "source": [
    "# 2 Этап 2. Реализация retrieval-системы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noTqEFRlQ_fq"
   },
   "outputs": [],
   "source": [
    "# from langchain_core.documents import Document\n",
    "# def load_from_list_of_dicts(data: list[dict]) -> list[Document]:\n",
    "#     \"\"\"\n",
    "#     Converts a list of dictionaries into a list of LangChain Document objects.\n",
    "\n",
    "#     Each dictionary is expected to have 'page_content' and optional 'metadata' keys.\n",
    "#     \"\"\"\n",
    "#     documents = []\n",
    "#     for item in data:\n",
    "#         page_content = item.get('title') + '\\n' + item.get('abstract')\n",
    "#         metadata = {'source': item.get('categories')}\n",
    "#         # Create a Document object\n",
    "#         doc = Document(page_content=page_content, metadata=metadata)\n",
    "#         documents.append(doc)\n",
    "#     return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1770311184871,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "8phSF6meQ_iU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 644,
     "status": "ok",
     "timestamp": 1770321947185,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "skZIBfIlQ_lX"
   },
   "outputs": [],
   "source": [
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    print(f'record = {record}')\n",
    "    print(f'record.keys() = {record.keys()}')\n",
    "    metadata[\"categories\"] = record[\"categories\"]\n",
    "    metadata[\"id\"] = record[\"id\"]\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1770322894102,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "UESBqxGbHfRf"
   },
   "outputs": [],
   "source": [
    "class RAG:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # embedder_name: str = \"intfloat/e5-base-v2\",\n",
    "        # reranker_name: str = \"cross-encoder/ms-marco-MiniLM-L-12-v2\",\n",
    "\n",
    "        embedder_name: str = \"Qwen/Qwen3-Embedding-0.6B\",\n",
    "        reranker_name: str = \"Qwen/Qwen3-Reranker-0.6B\",\n",
    "\n",
    "        # chunk_size: int = 500,\n",
    "        # chunk_overlap: int = 125,\n",
    "        device: Optional[str] = None,\n",
    "    ):\n",
    "        self.device = device or (\"cuda\"\n",
    "                                 if torch.cuda.is_available() else \"cpu\")\n",
    "        self.emb_tokenizer = AutoTokenizer.from_pretrained(embedder_name)\n",
    "        self.embedder = AutoModel.from_pretrained(embedder_name).to(\n",
    "            self.device)\n",
    "        self.embedder.eval()\n",
    "\n",
    "        self.rr_tokenizer = AutoTokenizer.from_pretrained(\n",
    "            reranker_name,\n",
    "            padding_side='left')\n",
    "        self.reranker = AutoModelForCausalLM.from_pretrained(\n",
    "            reranker_name).to(self.device)\n",
    "        self.reranker.eval()\n",
    "\n",
    "        # self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "        #     chunk_size=chunk_size,\n",
    "        #     chunk_overlap=chunk_overlap,\n",
    "        # )\n",
    "        self.index = None\n",
    "        self.doc_store = []\n",
    "\n",
    "        # self.max_length = 8192\n",
    "        self.max_length = 512\n",
    "        self.token_false_id = self.rr_tokenizer.convert_tokens_to_ids(\"no\")\n",
    "        self.token_true_id = self.rr_tokenizer.convert_tokens_to_ids(\"yes\")\n",
    "        prefix = \"<|im_start|>system\\nJudge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be \\\"yes\\\" or \\\"no\\\".<|im_end|>\\n<|im_start|>user\\n\"\n",
    "        suffix = \"<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n\"\n",
    "        self.prefix_tokens = self.rr_tokenizer.encode(prefix,\n",
    "                                                      add_special_tokens=False)\n",
    "        self.suffix_tokens = self.rr_tokenizer.encode(suffix,\n",
    "                                                      add_special_tokens=False)\n",
    "\n",
    "    def _generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        inputs = self.emb_tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=self.max_length,\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.embedder(**inputs)\n",
    "\n",
    "        inputs.to(\"cpu\")\n",
    "        embeddings = self.last_token_pool(outputs.last_hidden_state,\n",
    "                                          inputs.attention_mask).cpu()\n",
    "        return F.normalize(embeddings, p=2, dim=1).numpy()\n",
    "\n",
    "    @staticmethod\n",
    "    def last_token_pool(last_hidden_states: Tensor,\n",
    "                        attention_mask: Tensor) -> Tensor:\n",
    "        left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "        if left_padding:\n",
    "            return last_hidden_states[:, -1]\n",
    "        else:\n",
    "            sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "            batch_size = last_hidden_states.shape[0]\n",
    "            return last_hidden_states[\n",
    "                torch.arange(batch_size, device=last_hidden_states.device),\n",
    "                sequence_lengths]\n",
    "\n",
    "    # Define the metadata extraction function.\n",
    "\n",
    "\n",
    "    def load_and_process_file(self, file_path: str) -> List[Document]:\n",
    "        \"\"\"Загрузка и экстракция данных из файлов\"\"\"\n",
    "        ext = os.path.splitext(file_path)[1]\n",
    "        if ext == \".json\":\n",
    "            # loader = JSONLoader(\n",
    "            #   file_path=file_path,\n",
    "            #   jq_schema='.[]',\n",
    "            #   content_key=\"abstract\",\n",
    "            #   text_content=True,\n",
    "            #   # is_content_key_jq_parsable=True,\n",
    "            #   metadata_func=metadata_func\n",
    "            # )\n",
    "            loader = JSONLoader(\n",
    "              file_path=file_path,\n",
    "              jq_schema='.[] | {combined_content: (.title + \". \" + .abstract), categories: .categories}',\n",
    "              content_key=\"combined_content\",\n",
    "              text_content=True,\n",
    "              # is_content_key_jq_parsable=True,\n",
    "              metadata_func=metadata_func\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "        docs = loader.load()\n",
    "\n",
    "        # return self.text_splitter.split_documents(docs)\n",
    "        return docs\n",
    "\n",
    "\n",
    "    def build_index(self, file_paths: List[str], batch_size: int = 4) -> None:\n",
    "        \"\"\"Строим индекс FAISS\"\"\"\n",
    "        all_docs = []\n",
    "        for path in file_paths:\n",
    "            all_docs.extend(self.load_and_process_file(path))\n",
    "        self.doc_store = all_docs\n",
    "\n",
    "        # Вычислим numpy-эмбеддинги по батчам\n",
    "        embeddings = []\n",
    "        for i in tqdm(range(0, len(all_docs), batch_size)):\n",
    "            batch = [doc.page_content for doc in all_docs[i:i + batch_size]]\n",
    "            embeddings.append(self._generate_embeddings(batch))\n",
    "\n",
    "        embeddings = np.concatenate(embeddings)\n",
    "\n",
    "        # Инициализируем индекс\n",
    "        self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "        self.index.add(embeddings)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_detailed_instruct(task_description: str, query: str):\n",
    "        return f'Instruct: {task_description}\\nQuery:{query}'\n",
    "\n",
    "    @staticmethod\n",
    "    def format_reranker_instruction(query, doc, instruction=None):\n",
    "        if instruction is None:\n",
    "            instruction = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "        output = \"<Instruct>: {instruction}\\n<Query>: {query}\\n<Document>: {doc}\".format(\n",
    "            instruction=instruction, query=query, doc=doc)\n",
    "        return output\n",
    "\n",
    "    def process_inputs(self, pairs):\n",
    "        \"\"\"Обработка данных для реранкера\"\"\"\n",
    "        inputs = self.rr_tokenizer(pairs,\n",
    "                                   padding=False,\n",
    "                                   truncation='longest_first',\n",
    "                                   return_attention_mask=False,\n",
    "                                   max_length=self.max_length -\n",
    "                                   len(self.prefix_tokens) -\n",
    "                                   len(self.suffix_tokens))\n",
    "        for i, ele in enumerate(inputs['input_ids']):\n",
    "            inputs['input_ids'][\n",
    "                i] = self.prefix_tokens + ele + self.suffix_tokens\n",
    "        inputs = self.rr_tokenizer.pad(inputs,\n",
    "                                       padding=True,\n",
    "                                       return_tensors=\"pt\",\n",
    "                                       max_length=self.max_length)\n",
    "\n",
    "        # переносим тензоры на девайс ранжирующей модели\n",
    "        for key in inputs:\n",
    "            inputs[key] = inputs[key].to(self.device)\n",
    "        return inputs\n",
    "\n",
    "    def search(self,\n",
    "               query: str,\n",
    "               k: int = 5,\n",
    "               task: str = None):\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"Index not initialized\")\n",
    "\n",
    "        if task is None:\n",
    "            task = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "\n",
    "        query_embedding = self._generate_embeddings([query])\n",
    "        distances, indices = self.index.search(query_embedding, k)\n",
    "        return distances, indices\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_logits(self, inputs):\n",
    "        batch_scores = self.reranker(**inputs).logits[:, -1, :]\n",
    "        true_vector = batch_scores[:, self.token_true_id]\n",
    "        false_vector = batch_scores[:, self.token_false_id]\n",
    "        batch_scores = torch.stack([false_vector, true_vector], dim=1)\n",
    "        batch_scores = torch.nn.functional.log_softmax(batch_scores, dim=1)\n",
    "        scores = batch_scores[:, 1].exp().tolist()\n",
    "        return scores\n",
    "\n",
    "    def rerank(self, query: str, documents: List[str], batch_size=1):\n",
    "        pairs = []\n",
    "        for d in documents:\n",
    "            pairs.append(self.format_reranker_instruction(query, d))\n",
    "\n",
    "        scores = []\n",
    "        for i in range(0, len(pairs), batch_size):\n",
    "\n",
    "            inputs = self.process_inputs(pairs[i:i + batch_size])\n",
    "            sc = self.compute_logits(inputs)\n",
    "            scores.extend(sc)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index_next(my_list, target_value, not_found_value):\n",
    "    return next((i + 1 for i, x in enumerate(my_list) if x == target_value), not_found_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1770322400341,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "0ZC7an0HZ6wp"
   },
   "outputs": [],
   "source": [
    "# # освободим место на GPU\n",
    "# torch.cuda.empty_cache()\n",
    "# rag.embedder.to(\"cpu\")\n",
    "# rag.reranker.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2556,
     "status": "ok",
     "timestamp": 1770322404247,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "gFyJsDBLBHB3",
    "outputId": "1f09f189-5600-432a-e225-53d595fe8523"
   },
   "outputs": [],
   "source": [
    "rag = RAG(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18106,
     "status": "ok",
     "timestamp": 1770322426855,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "hRiz8p1iWzlN",
    "outputId": "a40830bd-ef7d-44b6-c410-2ea12ffd0aef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record = {'combined_content': 'The discrete dipole approximation: an overview and recent developments.   We present a review of the discrete dipole approximation (DDA), which is a\\ngeneral method to simulate light scattering by arbitrarily shaped particles. We\\nput the method in historical context and discuss recent developments, taking\\nthe viewpoint of a general framework based on the integral equations for the\\nelectric field. We review both the theory of the DDA and its numerical aspects,\\nthe latter being of critical importance for any practical application of the\\nmethod. Finally, the position of the DDA among other methods of light\\nscattering simulation is shown and possible future developments are discussed.\\n', 'categories': 'physics.optics physics.comp-ph'}\n",
      "record.keys() = dict_keys(['combined_content', 'categories'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# data_json_path,\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_sample_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# data_sample2_path,\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# data_sample4_path,\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[52], line 113\u001b[0m, in \u001b[0;36mRAG.build_index\u001b[0;34m(self, file_paths, batch_size)\u001b[0m\n\u001b[1;32m    111\u001b[0m all_docs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m file_paths:\n\u001b[0;32m--> 113\u001b[0m     all_docs\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_and_process_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_store \u001b[38;5;241m=\u001b[39m all_docs\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Вычислим numpy-эмбеддинги по батчам\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[52], line 103\u001b[0m, in \u001b[0;36mRAG.load_and_process_file\u001b[0;34m(self, file_path)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported file type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 103\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# return self.text_splitter.split_documents(docs)\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/langchain_core/document_loaders/base.py:32\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/langchain_community/document_loaders/json_loader.py:147\u001b[0m, in \u001b[0;36mJSONLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;241m.\u001b[39mread_text(encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m\"\u001b[39m), index\n\u001b[1;32m    149\u001b[0m     ):\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m doc\n\u001b[1;32m    151\u001b[0m         index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/langchain_community/document_loaders/json_loader.py:165\u001b[0m, in \u001b[0;36mJSONLoader._parse\u001b[0;34m(self, content, index)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data, index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    164\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_text(sample\u001b[38;5;241m=\u001b[39msample)\n\u001b[0;32m--> 165\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m Document(page_content\u001b[38;5;241m=\u001b[39mtext, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/langchain_community/document_loaders/json_loader.py:206\u001b[0m, in \u001b[0;36mJSONLoader._get_metadata\u001b[0;34m(self, sample, **additional_fields)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mReturn a metadata dictionary base on the existence of metadata_func\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m:param sample: single data payload\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param additional_fields: key-word arguments to be added as metadata values\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metadata_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_fields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    209\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected the metadata_func to return a dict but got \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124m                        `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m         )\n",
      "Cell \u001b[0;32mIn[51], line 5\u001b[0m, in \u001b[0;36mmetadata_func\u001b[0;34m(record, metadata)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecord.keys() = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mrecord\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metadata\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "rag.build_index(\n",
    "    [\n",
    "        # data_json_path,\n",
    "\n",
    "        data_sample_path,\n",
    "        # data_sample2_path,\n",
    "        # data_sample4_path,\n",
    "        \n",
    "    ],\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_check_idx = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1770322573091,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "E2-OTJcHcirx",
    "outputId": "553c2c9f-3107-4d97-f223-d627980eb5c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the primary challenge of the newly developed German ADR detection corpus in terms of its annotation?',\n",
       " '2208.02031',\n",
       " '  In this work, we present the first corpus for German Adverse Drug Reaction\\n(ADR) detection in patient-generated content. The data consists of 4,169 binary\\nannotated documents from a German patient forum, where users talk about health\\nissues and get advice from medical doctors. As is common in social media data\\nin this domain, the class labels of the corpus are very imbalanced. This and a\\nhigh topic imbalance make it a very challenging dataset, since often, the same\\nsymptom can have several causes and is not always related to a medication\\nintake. We aim to encourage further multi-lingual efforts in the domain of ADR\\ndetection and provide preliminary experiments for binary classification using\\ndifferent methods of zero- and few-shot learning based on a multi-lingual\\nmodel. When fine-tuning XLM-RoBERTa first on English patient forum data and\\nthen on the new German data, we achieve an F1-score of 37.52 for the positive\\nclass. We make the dataset and models publicly available for the community.\\n')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = df_test.loc[test_check_idx, 'query']\n",
    "answer = df_test.loc[test_check_idx, 'abstract']\n",
    "id_true = df_test.loc[test_check_idx, 'id']\n",
    "q, id_true, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2208.02031\n"
     ]
    }
   ],
   "source": [
    "for i, elem in enumerate(sample_data4):\n",
    "    if elem['id'] == id_true:\n",
    "        print(i, elem['id'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_cands = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1770322584198,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "gecGSp4Ociui"
   },
   "outputs": [],
   "source": [
    "_, I = rag.search(q, k=k_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1770322624491,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "Gh0HTnu0cwsD"
   },
   "outputs": [],
   "source": [
    "candidates = [rag.doc_store[i].page_content for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7783, 3821, 1243, 2657, 7464])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/home/ubuntu/practicum_dle_sprint_7/nlp_s3_project/sample_data.json', 'seq_num': 40, 'categories': 'gr-qc', 'id': '0704.0849'}, page_content='  An LRS Bianchi type-V cosmological models representing a viscous fluid\\ndistribution with a time dependent cosmological term $\\\\Lambda$ is investigated.\\nTo get a determinate solution, the viscosity coefficient of bulk viscous fluid\\nis assumed to be a power function of mass density. It turns out that the\\ncosmological term $\\\\Lambda(t)$ is a decreasing function of time, which is\\nconsistent with recent observations of type Ia supernovae. Various physical and\\nkinematic features of these models have also been explored.\\n')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.doc_store[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_flags = [rag.doc_store[i].metadata['id'] == id_true for i in I[0]]\n",
    "find_index_next(relevant_flags, True, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1770322630410,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "xULG5E8-cixP"
   },
   "outputs": [],
   "source": [
    "k_ranked = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1770322682389,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "CmSG_UDxdEFU",
    "outputId": "7901c471-c3a7-43cc-e0ca-342e711139a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Introduction to the Special Issue: Genome-Wide Association Studies\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "error",
     "timestamp": 1770322896604,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "072dIu1dc50f",
    "outputId": "f8597c0a-657c-4f63-b069-7179e0f1957e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/ubuntu/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scores = rag.rerank(q, candidates)\n",
    "array = np.array(scores)\n",
    "indices = np.argsort(array)[::-1][:k_ranked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 4, 3, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1243, 7783, 7464, 2657, 3821]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_ids = [int(I[0][i]) for i in indices]\n",
    "ranked_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_flags = [rag.doc_store[i].metadata['id'] == id_true for i in ranked_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_index_next(relevant_flags, True, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Index not initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m q \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m id_true \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m _, I \u001b[38;5;241m=\u001b[39m \u001b[43mrag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_cands_rerank\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m candidates \u001b[38;5;241m=\u001b[39m [rag\u001b[38;5;241m.\u001b[39mdoc_store[i]\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m I[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m     13\u001b[0m scores \u001b[38;5;241m=\u001b[39m rag\u001b[38;5;241m.\u001b[39mrerank(q, candidates)\n",
      "Cell \u001b[0;32mIn[45], line 167\u001b[0m, in \u001b[0;36mRAG.search\u001b[0;34m(self, query, k, task)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    163\u001b[0m            query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    164\u001b[0m            k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m    165\u001b[0m            task: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex not initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m         task \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGiven a web search query, retrieve relevant passages that answer the query\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Index not initialized"
     ]
    }
   ],
   "source": [
    "K_mrr = 5\n",
    "N_cands_rerank = 5\n",
    "\n",
    "mrr5_list = []\n",
    "for j, row in tqdm(df_test[:100].iterrows()):\n",
    "  # print(index, row['id'])\n",
    "  q = row['query']\n",
    "  id_true = row['id']\n",
    "\n",
    "\n",
    "  _, I = rag.search(q, k=N_cands_rerank)\n",
    "  candidates = [rag.doc_store[i].page_content for i in I[0]]\n",
    "  scores = rag.rerank(q, candidates)\n",
    "  array = np.array(scores)\n",
    "  indices = np.argsort(array)[::-1][:K_mrr]\n",
    "  ranked_ids = [int(I[0][i]) for i in indices]\n",
    "\n",
    "  relevant_flags = [rag.doc_store[i].metadata['id'] == id_true for i in ranked_ids]   # i in I[0]]\n",
    "  relev_index = find_index_next(relevant_flags, True, np.inf)\n",
    "\n",
    "  mrr5_step = 1 / relev_index\n",
    "  if mrr5_step > 0 :\n",
    "    print(f'j={j}, relev_index = {relev_index}, mrr5_step={mrr5_step}')\n",
    "  mrr5_list.append(mrr5_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:03,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=5, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:08,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=13, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:13,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=22, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:23,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=38, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:24,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=39, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [00:34,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=56, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62it [00:37,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=61, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [00:46,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=75, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:47,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=78, relev_index = 2, mrr5_step=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90it [00:54,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=89, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "K_mrr = 5\n",
    "N_cands_rerank = 5\n",
    "\n",
    "mrr5_list = []\n",
    "for j, row in tqdm(df_test[:100].iterrows()):\n",
    "  # print(index, row['id'])\n",
    "  q = row['query']\n",
    "  id_true = row['id']\n",
    "\n",
    "\n",
    "  _, I = rag.search(q, k=N_cands_rerank)\n",
    "  candidates = [rag.doc_store[i].page_content for i in I[0]]\n",
    "  scores = rag.rerank(q, candidates)\n",
    "  array = np.array(scores)\n",
    "  indices = np.argsort(array)[::-1][:K_mrr]\n",
    "  ranked_ids = [int(I[0][i]) for i in indices]\n",
    "\n",
    "  relevant_flags = [rag.doc_store[i].metadata['id'] == id_true for i in ranked_ids]   # i in I[0]]\n",
    "  relev_index = find_index_next(relevant_flags, True, np.inf)\n",
    "\n",
    "  mrr5_step = 1 / relev_index\n",
    "  if mrr5_step > 0 :\n",
    "    print(f'j={j}, relev_index = {relev_index}, mrr5_step={mrr5_step}')\n",
    "  mrr5_list.append(mrr5_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1770320952265,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "1moNxqdUS1kb",
    "outputId": "144ab6d9-41fc-4aa2-85c2-3ddbe88eb841"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.095"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MRR5 = sum(mrr5_list) / len(mrr5_list)\n",
    "MRR5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1770320952305,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "sXcG7r8jSqMu",
    "outputId": "a6470f1c-29ca-4178-8005-6cb513f4db4f"
   },
   "outputs": [],
   "source": [
    "1 / np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1770318081143,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "EFMGV40ULgdO",
    "outputId": "321741eb-bff4-4337-c160-77b64b0e194b"
   },
   "outputs": [],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1770319204848,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "1NU1TeDSMBc1",
    "outputId": "5ad0178a-6674-4210-e118-5811ad87a972"
   },
   "outputs": [],
   "source": [
    "relevant_flags = [rag.doc_store[i].metadata['id'] == id_true for i in I[0]]\n",
    "relevant_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1770319608138,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "7xaA5lXWRBhH"
   },
   "outputs": [],
   "source": [
    "relevant_flags = [True, False, False, True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1770319621759,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "DnS4u8J0Q11O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1770319625407,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "MBnRhe3ORKMA",
    "outputId": "92ac5bd3-1d38-42eb-c0be-84210f35d26b"
   },
   "outputs": [],
   "source": [
    "find_index_next(relevant_flags, True, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1770319538894,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "uAO0NxF5QwZf",
    "outputId": "efc373ba-755a-4b31-fc7d-28a4e7967270"
   },
   "outputs": [],
   "source": [
    "find_index_or_none_next(relevant_flags, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "error",
     "timestamp": 1770319369297,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "uVbO_PyaQVS4",
    "outputId": "d151c97f-7631-4d91-c050-91ed9f79af4d"
   },
   "outputs": [],
   "source": [
    "relevant_flags.index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25JolnvVP1qx"
   },
   "outputs": [],
   "source": [
    "mrr@5 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1770319307310,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "BSlPErjtQKxD",
    "outputId": "da021df8-9ceb-4b67-b2a4-0f96c4eaef2c"
   },
   "outputs": [],
   "source": [
    "next((item for item in relevant_flags if item), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1770319176976,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "1V7d-jU6Pryc",
    "outputId": "cb7018f0-cb61-4d23-c716-a9b7cb44b976"
   },
   "outputs": [],
   "source": [
    "[rag.doc_store[i].metadata['id'] for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHoPP_G_Lis2"
   },
   "outputs": [],
   "source": [
    "candidates = [rag.doc_store[i].page_content for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1770318236862,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "rq892e6TLy5E",
    "outputId": "94e7cae6-0a74-420c-b9dd-ab92255d8887"
   },
   "outputs": [],
   "source": [
    "rag.doc_store[23].metadata['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCcqHi-8L0gH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP4tEok5cit2ymCUEuNxYP9",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
