{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6638,
     "status": "ok",
     "timestamp": 1770321834001,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "dA2WtJrxNI7R",
    "outputId": "0614f29f-f1b3-4268-d6f7-cea585ea2dec"
   },
   "outputs": [],
   "source": [
    "# pip install faiss-gpu-cu12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4578,
     "status": "ok",
     "timestamp": 1770321838593,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "qCzoOzuCNJn8",
    "outputId": "c90124e5-b8c0-4eb3-a267-9adf0ff72a82"
   },
   "outputs": [],
   "source": [
    "# pip install langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16475,
     "status": "ok",
     "timestamp": 1770321855069,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "XIDosRe-NOCL",
    "outputId": "da426736-2d7d-45c9-c592-c2a1dcc1c7ad"
   },
   "outputs": [],
   "source": [
    "# pip install langchain-huggingface sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9353,
     "status": "ok",
     "timestamp": 1770321864423,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "Vm52otLQNp6w",
    "outputId": "3e907d49-4706-40db-d2d6-834570691061"
   },
   "outputs": [],
   "source": [
    "# pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4644,
     "status": "ok",
     "timestamp": 1770321869069,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "RRGiS1sVNOJF",
    "outputId": "0f81e53f-4b01-4d7a-a767-843a5d9ee64f"
   },
   "outputs": [],
   "source": [
    "# pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4778,
     "status": "ok",
     "timestamp": 1770321873848,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "mfj35bz6XFah",
    "outputId": "982b7359-9969-4f89-b514-b272eded974c"
   },
   "outputs": [],
   "source": [
    "# pip install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1770321873904,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "IX9rn8gcNXxL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 25188,
     "status": "ok",
     "timestamp": 1770321899093,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "GBFYOC-GNX0Y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional, Dict\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    TextLoader,\n",
    "    JSONLoader\n",
    ")\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2549,
     "status": "ok",
     "timestamp": 1770321912827,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "nrnn_bzQ5DUs",
    "outputId": "1a6ffc30-6c9d-405c-cd7e-f056e01d5396"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1770321912844,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "NoIT4WGKz1NA"
   },
   "outputs": [],
   "source": [
    "# main_path = '/content/drive/MyDrive/PRACTICUM_DLE/sprint_7/'\n",
    "main_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0_3463K4eTf"
   },
   "source": [
    "# 1 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1770321915941,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "l5K5Uoc64hoH"
   },
   "outputs": [],
   "source": [
    "data_path = main_path + 'nlp_s3_project/'\n",
    "\n",
    "data_json_path = data_path + 'arxiv-metadata-s.json'\n",
    "data_csv_path = data_path + 'test_sample.csv'\n",
    "\n",
    "data_sample_path = data_path + 'sample_data.json'\n",
    "data_sample2_path = data_path + 'sample_data2.json'\n",
    "data_sample3_path = data_path + 'sample_data3.json'\n",
    "data_sample4_path = data_path + 'sample_data4.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path + 'sample_data.json', 'w') as file:\n",
    "#   json.dump(train_data[:10000], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 8578,
     "status": "ok",
     "timestamp": 1770321925691,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "d6qe4U1h0j_A"
   },
   "outputs": [],
   "source": [
    "with open(data_json_path, 'r') as file:\n",
    "  train_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1770321926595,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "X3zhk7Z7X3Yl"
   },
   "outputs": [],
   "source": [
    "with open(data_sample_path, 'r') as file:\n",
    "  sample_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_sample2_path, 'r') as file:\n",
    "  sample_data2 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_sample3_path, 'r') as file:\n",
    "  sample_data3 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_sample4_path, 'r') as file:\n",
    "  sample_data4 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1770321936957,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "6foFcmfgaN5x",
    "outputId": "3dd4c2dd-c42e-4a5f-f644-9b17bfca38ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 505, 100, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_data), len(sample_data2), len(sample_data3), len(sample_data4), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 429,
     "status": "ok",
     "timestamp": 1770321927026,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "5jGPAH4vVhc1"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(data_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_test[:100]['id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our_ids = []\n",
    "# for i, elem in tqdm(enumerate(train_data)):\n",
    "#     if elem['id'] in df_test[:100]['id'].tolist():\n",
    "#         # print(i)\n",
    "#         our_ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our_ids = []\n",
    "# for j, row in tqdm(df_test[:100].iterrows()):\n",
    "#     for i, elem in (enumerate(train_data)):\n",
    "#         if elem['id'] == row['id']:\n",
    "#             our_ids.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_data4 = [train_data[i] for i in our_ids] #+ random.sample(train_data, 100)\n",
    "# len(sample_data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_data4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path + 'sample_data4.json', 'w') as file:\n",
    "#   json.dump(sample_data4, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2412.16732</td>\n",
       "      <td>A new platinate was recently discovered when...</td>\n",
       "      <td>What unique composition and decomposition beha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nucl-th/9602019</td>\n",
       "      <td>The production cross sections of various fra...</td>\n",
       "      <td>How does the inclusion of statistical decay af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2501.05500</td>\n",
       "      <td>This survey provides a comprehensive examina...</td>\n",
       "      <td>What are the core components of modern zero-kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2506.20892</td>\n",
       "      <td>A critical challenge for operating fusion burn...</td>\n",
       "      <td>How does impurity seeding affect the timing an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2208.02031</td>\n",
       "      <td>In this work, we present the first corpus fo...</td>\n",
       "      <td>What is the primary challenge of the newly dev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                           abstract  \\\n",
       "0       2412.16732    A new platinate was recently discovered when...   \n",
       "1  nucl-th/9602019    The production cross sections of various fra...   \n",
       "2       2501.05500    This survey provides a comprehensive examina...   \n",
       "3       2506.20892  A critical challenge for operating fusion burn...   \n",
       "4       2208.02031    In this work, we present the first corpus fo...   \n",
       "\n",
       "                                               query  \n",
       "0  What unique composition and decomposition beha...  \n",
       "1  How does the inclusion of statistical decay af...  \n",
       "2  What are the core components of modern zero-kn...  \n",
       "3  How does impurity seeding affect the timing an...  \n",
       "4  What is the primary challenge of the newly dev...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1770321927049,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "8INRHTsQCPuX"
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(random.sample(train_data, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1770321927140,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "usD-1ZVoCTht",
    "outputId": "00765c0a-11f5-4c62-cbbf-3e817190a2e2"
   },
   "outputs": [],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qv9vpagRGgq6"
   },
   "source": [
    "## title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82145,
     "status": "aborted",
     "timestamp": 1770321909193,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "eEZ7ZwATGbu9"
   },
   "outputs": [],
   "source": [
    "df_train['title'].apply(lambda x: len(x.split())).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['title'].str.len().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82144,
     "status": "aborted",
     "timestamp": 1770321909193,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "txtdL29WG833"
   },
   "outputs": [],
   "source": [
    "df_train['abstract'].apply(lambda x: len(x.split())).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['abstract'].str.len().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_name = \"Qwen/Qwen3-Embedding-0.6B\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "emb_tokenizer = AutoTokenizer.from_pretrained(embedder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rezu = emb_tokenizer(df_train['abstract'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rezu.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(tk) for tk in rezu['input_ids']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(tk) for tk in rezu['input_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzNIegDkGcwi"
   },
   "source": [
    "## submitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82142,
     "status": "aborted",
     "timestamp": 1770321909194,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "GFI5nUJYCfMX"
   },
   "outputs": [],
   "source": [
    "df_train['submitter'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJP8fap1DbDb"
   },
   "source": [
    "## tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82143,
     "status": "aborted",
     "timestamp": 1770321909199,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "YZItX6BeDZDl"
   },
   "outputs": [],
   "source": [
    "categories_dict = {}\n",
    "for cats in df_train['categories']:\n",
    "  for cat in cats.split():\n",
    "    if cat in categories_dict:\n",
    "      categories_dict[cat] += 1\n",
    "    else:\n",
    "      categories_dict[cat] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82142,
     "status": "aborted",
     "timestamp": 1770321909199,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "RNMbH7EMD-co"
   },
   "outputs": [],
   "source": [
    "df_cats = pd.DataFrame([[k, v] for k, v in categories_dict.items()], columns=['category', 'count']).sort_values('count', ascending=False).reset_index(drop=True)\n",
    "df_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82141,
     "status": "aborted",
     "timestamp": 1770321909200,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "p5vFvcBJF0On"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82141,
     "status": "aborted",
     "timestamp": 1770321909201,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "pQ9EhxV4F0Ry"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82139,
     "status": "aborted",
     "timestamp": 1770321909201,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "mOVtmeZ4FJ3t"
   },
   "outputs": [],
   "source": [
    "df_train['categories'].apply(lambda x: len(x.split())).value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2OfTqfOFxOu"
   },
   "source": [
    "## update_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82139,
     "status": "aborted",
     "timestamp": 1770321909202,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "23KNAPxuFJ6d"
   },
   "outputs": [],
   "source": [
    "pd.to_datetime(df_train['update_date']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82138,
     "status": "aborted",
     "timestamp": 1770321909202,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "TCnPfXymFu7y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53dzcwpOFvty"
   },
   "source": [
    "## versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82137,
     "status": "aborted",
     "timestamp": 1770321909203,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "wGtMfS3aFgc_"
   },
   "outputs": [],
   "source": [
    "df_train['versions'].apply(lambda x: len(x)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0dokDwRGHXf"
   },
   "source": [
    "## authors_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82136,
     "status": "aborted",
     "timestamp": 1770321909203,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "ZVqA4IXHGLTn"
   },
   "outputs": [],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82135,
     "status": "aborted",
     "timestamp": 1770321909204,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "OeIvFDsYCxv-"
   },
   "outputs": [],
   "source": [
    "df_train['authors_parsed'].apply(lambda x: len(x)).value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82134,
     "status": "aborted",
     "timestamp": 1770321909204,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "JngWUWEWGTwl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npQCUHtCHKYs"
   },
   "source": [
    "## 1.2 Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82148,
     "status": "aborted",
     "timestamp": 1770321909221,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "d6-H6VKu0kCE"
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82148,
     "status": "aborted",
     "timestamp": 1770321909222,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "HnhBXz_ZHbj2"
   },
   "outputs": [],
   "source": [
    "df_test.loc[0, 'query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82157,
     "status": "aborted",
     "timestamp": 1770321909232,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "w7c9XdxKHcIm"
   },
   "outputs": [],
   "source": [
    "df_test.loc[0, 'abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82167,
     "status": "aborted",
     "timestamp": 1770321909243,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "wE5ybziwHOlp"
   },
   "outputs": [],
   "source": [
    "df_test['abstract'].apply(lambda x: len(x.split())).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82166,
     "status": "aborted",
     "timestamp": 1770321909244,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "EHBy5A6-HWnM"
   },
   "outputs": [],
   "source": [
    "df_test['query'].apply(lambda x: len(x.split())).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTvwilEgHpvK"
   },
   "source": [
    "# Выводы по EDA\n",
    "\n",
    "1. как вы будете решать задачу;\n",
    "- Сделаем RAG+LLM\n",
    "2. какие подходы к поиску примените и почему;\n",
    "- Графовая БД index какой-то\n",
    "3. какие модели выберете и от каких ограничений будете отталкиваться;\n",
    "- Как в примерах\n",
    "4. из чего будет состоять ваша система.\n",
    "- Загрузчик данных\n",
    "- Ембеддер данных\n",
    "- БДшка векторная и индекс\n",
    "- функция поиска релевантных данных к запросу\n",
    "- функция ранжирования релеввантных\n",
    "- Формирование комби запроса с учетом релевантных\n",
    "- Инференс с ЛЛМ\n",
    "- расчет метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbuvhN7WIyH9"
   },
   "source": [
    "# 2 Этап 2. Реализация retrieval-системы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noTqEFRlQ_fq"
   },
   "outputs": [],
   "source": [
    "# from langchain_core.documents import Document\n",
    "# def load_from_list_of_dicts(data: list[dict]) -> list[Document]:\n",
    "#     \"\"\"\n",
    "#     Converts a list of dictionaries into a list of LangChain Document objects.\n",
    "\n",
    "#     Each dictionary is expected to have 'page_content' and optional 'metadata' keys.\n",
    "#     \"\"\"\n",
    "#     documents = []\n",
    "#     for item in data:\n",
    "#         page_content = item.get('title') + '\\n' + item.get('abstract')\n",
    "#         metadata = {'source': item.get('categories')}\n",
    "#         # Create a Document object\n",
    "#         doc = Document(page_content=page_content, metadata=metadata)\n",
    "#         documents.append(doc)\n",
    "#     return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1770311184871,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "8phSF6meQ_iU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 644,
     "status": "ok",
     "timestamp": 1770321947185,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "skZIBfIlQ_lX"
   },
   "outputs": [],
   "source": [
    "def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "    metadata[\"categories\"] = record[\"categories\"]\n",
    "    metadata[\"id\"] = record[\"id\"]\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1770322894102,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "UESBqxGbHfRf"
   },
   "outputs": [],
   "source": [
    "class RAG:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # embedder_name: str = \"intfloat/e5-base-v2\",\n",
    "        # reranker_name: str = \"cross-encoder/ms-marco-MiniLM-L-12-v2\",\n",
    "\n",
    "        embedder_name: str = \"Qwen/Qwen3-Embedding-0.6B\",\n",
    "        reranker_name: str = \"Qwen/Qwen3-Reranker-0.6B\",\n",
    "\n",
    "        # chunk_size: int = 500,\n",
    "        # chunk_overlap: int = 125,\n",
    "        device: Optional[str] = None,\n",
    "    ):\n",
    "        self.device = device or (\"cuda\"\n",
    "                                 if torch.cuda.is_available() else \"cpu\")\n",
    "        self.emb_tokenizer = AutoTokenizer.from_pretrained(embedder_name)\n",
    "        self.embedder = AutoModel.from_pretrained(embedder_name).to(\n",
    "            self.device)\n",
    "        self.embedder.eval()\n",
    "\n",
    "        self.rr_tokenizer = AutoTokenizer.from_pretrained(\n",
    "            reranker_name,\n",
    "            padding_side='left')\n",
    "        self.reranker = AutoModelForCausalLM.from_pretrained(\n",
    "            reranker_name).to(self.device)\n",
    "        self.reranker.eval()\n",
    "\n",
    "        # self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "        #     chunk_size=chunk_size,\n",
    "        #     chunk_overlap=chunk_overlap,\n",
    "        # )\n",
    "        self.index = None\n",
    "        self.doc_store = []\n",
    "\n",
    "        # self.max_length = 8192\n",
    "        self.max_length = 512\n",
    "        self.token_false_id = self.rr_tokenizer.convert_tokens_to_ids(\"no\")\n",
    "        self.token_true_id = self.rr_tokenizer.convert_tokens_to_ids(\"yes\")\n",
    "        prefix = \"<|im_start|>system\\nJudge whether the Document meets the requirements based on the Query and the Instruct provided. Note that the answer can only be \\\"yes\\\" or \\\"no\\\".<|im_end|>\\n<|im_start|>user\\n\"\n",
    "        suffix = \"<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\n\"\n",
    "        self.prefix_tokens = self.rr_tokenizer.encode(prefix,\n",
    "                                                      add_special_tokens=False)\n",
    "        self.suffix_tokens = self.rr_tokenizer.encode(suffix,\n",
    "                                                      add_special_tokens=False)\n",
    "\n",
    "    def _generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        inputs = self.emb_tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=self.max_length,\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.embedder(**inputs)\n",
    "\n",
    "        inputs.to(\"cpu\")\n",
    "        embeddings = self.last_token_pool(outputs.last_hidden_state,\n",
    "                                          inputs.attention_mask).cpu()\n",
    "        return F.normalize(embeddings, p=2, dim=1).numpy()\n",
    "\n",
    "    @staticmethod\n",
    "    def last_token_pool(last_hidden_states: Tensor,\n",
    "                        attention_mask: Tensor) -> Tensor:\n",
    "        left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "        if left_padding:\n",
    "            return last_hidden_states[:, -1]\n",
    "        else:\n",
    "            sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "            batch_size = last_hidden_states.shape[0]\n",
    "            return last_hidden_states[\n",
    "                torch.arange(batch_size, device=last_hidden_states.device),\n",
    "                sequence_lengths]\n",
    "\n",
    "    # Define the metadata extraction function.\n",
    "\n",
    "\n",
    "    def load_and_process_file(self, file_path: str) -> List[Document]:\n",
    "        \"\"\"Загрузка и экстракция данных из файлов\"\"\"\n",
    "        ext = os.path.splitext(file_path)[1]\n",
    "        if ext == \".json\":\n",
    "            loader = JSONLoader(\n",
    "              file_path=file_path,\n",
    "              jq_schema='.[]',\n",
    "              content_key=\"abstract\",\n",
    "              text_content=True,\n",
    "              # is_content_key_jq_parsable=True,\n",
    "              metadata_func=metadata_func\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "        docs = loader.load()\n",
    "\n",
    "        # return self.text_splitter.split_documents(docs)\n",
    "        return docs\n",
    "\n",
    "\n",
    "    def build_index(self, file_paths: List[str], batch_size: int = 4) -> None:\n",
    "        \"\"\"Строим индекс FAISS\"\"\"\n",
    "        all_docs = []\n",
    "        for path in file_paths:\n",
    "            all_docs.extend(self.load_and_process_file(path))\n",
    "        self.doc_store = all_docs\n",
    "\n",
    "        # Вычислим numpy-эмбеддинги по батчам\n",
    "        embeddings = []\n",
    "        for i in tqdm(range(0, len(all_docs), batch_size)):\n",
    "            batch = [doc.page_content for doc in all_docs[i:i + batch_size]]\n",
    "            embeddings.append(self._generate_embeddings(batch))\n",
    "\n",
    "        embeddings = np.concatenate(embeddings)\n",
    "\n",
    "        # Инициализируем индекс\n",
    "        self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "        self.index.add(embeddings)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_detailed_instruct(task_description: str, query: str):\n",
    "        return f'Instruct: {task_description}\\nQuery:{query}'\n",
    "\n",
    "    @staticmethod\n",
    "    def format_reranker_instruction(query, doc, instruction=None):\n",
    "        if instruction is None:\n",
    "            instruction = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "        output = \"<Instruct>: {instruction}\\n<Query>: {query}\\n<Document>: {doc}\".format(\n",
    "            instruction=instruction, query=query, doc=doc)\n",
    "        return output\n",
    "\n",
    "    def process_inputs(self, pairs):\n",
    "        \"\"\"Обработка данных для реранкера\"\"\"\n",
    "        inputs = self.rr_tokenizer(pairs,\n",
    "                                   padding=False,\n",
    "                                   truncation='longest_first',\n",
    "                                   return_attention_mask=False,\n",
    "                                   max_length=self.max_length -\n",
    "                                   len(self.prefix_tokens) -\n",
    "                                   len(self.suffix_tokens))\n",
    "        for i, ele in enumerate(inputs['input_ids']):\n",
    "            inputs['input_ids'][\n",
    "                i] = self.prefix_tokens + ele + self.suffix_tokens\n",
    "        inputs = self.rr_tokenizer.pad(inputs,\n",
    "                                       padding=True,\n",
    "                                       return_tensors=\"pt\",\n",
    "                                       max_length=self.max_length)\n",
    "\n",
    "        # переносим тензоры на девайс ранжирующей модели\n",
    "        for key in inputs:\n",
    "            inputs[key] = inputs[key].to(self.device)\n",
    "        return inputs\n",
    "\n",
    "    def search(self,\n",
    "               query: str,\n",
    "               k: int = 5,\n",
    "               task: str = None):\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"Index not initialized\")\n",
    "\n",
    "        if task is None:\n",
    "            task = 'Given a web search query, retrieve relevant passages that answer the query'\n",
    "\n",
    "        query_embedding = self._generate_embeddings([query])\n",
    "        distances, indices = self.index.search(query_embedding, k)\n",
    "        return distances, indices\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def compute_logits(self, inputs):\n",
    "        batch_scores = self.reranker(**inputs).logits[:, -1, :]\n",
    "        true_vector = batch_scores[:, self.token_true_id]\n",
    "        false_vector = batch_scores[:, self.token_false_id]\n",
    "        batch_scores = torch.stack([false_vector, true_vector], dim=1)\n",
    "        batch_scores = torch.nn.functional.log_softmax(batch_scores, dim=1)\n",
    "        scores = batch_scores[:, 1].exp().tolist()\n",
    "        return scores\n",
    "\n",
    "    def rerank(self, query: str, documents: List[str], batch_size=1):\n",
    "        pairs = []\n",
    "        for d in documents:\n",
    "            pairs.append(self.format_reranker_instruction(query, d))\n",
    "\n",
    "        scores = []\n",
    "        for i in range(0, len(pairs), batch_size):\n",
    "\n",
    "            inputs = self.process_inputs(pairs[i:i + batch_size])\n",
    "            sc = self.compute_logits(inputs)\n",
    "            scores.extend(sc)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index_next(my_list, target_value, not_found_value):\n",
    "    return next((i + 1 for i, x in enumerate(my_list) if x == target_value), not_found_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1770322400341,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "0ZC7an0HZ6wp"
   },
   "outputs": [],
   "source": [
    "# # освободим место на GPU\n",
    "# torch.cuda.empty_cache()\n",
    "# rag.embedder.to(\"cpu\")\n",
    "# rag.reranker.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2556,
     "status": "ok",
     "timestamp": 1770322404247,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "gFyJsDBLBHB3",
    "outputId": "1f09f189-5600-432a-e225-53d595fe8523"
   },
   "outputs": [],
   "source": [
    "rag = RAG(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18106,
     "status": "ok",
     "timestamp": 1770322426855,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "hRiz8p1iWzlN",
    "outputId": "a40830bd-ef7d-44b6-c410-2ea12ffd0aef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 13.47it/s]\n"
     ]
    }
   ],
   "source": [
    "rag.build_index(\n",
    "    [\n",
    "        # data_json_path,\n",
    "\n",
    "        # data_sample_path,\n",
    "        # data_sample2_path,\n",
    "\n",
    "        data_sample4_path,\n",
    "        \n",
    "    ],\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_check_idx = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1770322573091,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "E2-OTJcHcirx",
    "outputId": "553c2c9f-3107-4d97-f223-d627980eb5c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What is the primary challenge of the newly developed German ADR detection corpus in terms of its annotation?',\n",
       " '2208.02031',\n",
       " '  In this work, we present the first corpus for German Adverse Drug Reaction\\n(ADR) detection in patient-generated content. The data consists of 4,169 binary\\nannotated documents from a German patient forum, where users talk about health\\nissues and get advice from medical doctors. As is common in social media data\\nin this domain, the class labels of the corpus are very imbalanced. This and a\\nhigh topic imbalance make it a very challenging dataset, since often, the same\\nsymptom can have several causes and is not always related to a medication\\nintake. We aim to encourage further multi-lingual efforts in the domain of ADR\\ndetection and provide preliminary experiments for binary classification using\\ndifferent methods of zero- and few-shot learning based on a multi-lingual\\nmodel. When fine-tuning XLM-RoBERTa first on English patient forum data and\\nthen on the new German data, we achieve an F1-score of 37.52 for the positive\\nclass. We make the dataset and models publicly available for the community.\\n')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = df_test.loc[test_check_idx, 'query']\n",
    "answer = df_test.loc[test_check_idx, 'abstract']\n",
    "id_true = df_test.loc[test_check_idx, 'id']\n",
    "q, id_true, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2208.02031\n"
     ]
    }
   ],
   "source": [
    "for i, elem in enumerate(sample_data4):\n",
    "    if elem['id'] == id_true:\n",
    "        print(i, elem['id'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_cands = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1770322584198,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "gecGSp4Ociui"
   },
   "outputs": [],
   "source": [
    "_, I = rag.search(q, k=k_cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1770322624491,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "Gh0HTnu0cwsD"
   },
   "outputs": [],
   "source": [
    "candidates = [rag.doc_store[i].page_content for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 86, 18, 20, 80])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/home/ubuntu/practicum_dle_sprint_7/nlp_s3_project/sample_data4.json', 'seq_num': 40, 'categories': 'astro-ph', 'id': '0809.4362'}, page_content='  We used the red clump stars from the photometric data of the Optical\\nGravitational Lensing Experiment(OGLE II) survey and the Magellanic Cloud\\nPhotometric Survey (MCPS) for both the Clouds to estimate the depth.The\\nobserved dispersion in the magnitude and colour distribution of red clump stars\\nis used to estimate the depth, after correcting for population effects,\\ninternal reddening within the Clouds and photometric errors.The observed\\ndispersion due to the line of sight depth ranges from 0.023 mag to 0.45 mag (a\\ndepth of 500 pc to 10.4 kpc) for LMC and from 0.025 to 0.34 magnitude(a depth\\nof 670 pc to 9.53 kpc).The depth profile of the LMC bar indicates that it is\\nflared.The average depth in the bar region is 4.0$\\\\pm$1.4 kpc. The northern\\ndisk is found to have depth(4.17$\\\\pm$0.97 kpc)larger than the southern part of\\nthe disk (2.63$\\\\pm$0.8kpc).There is no indication of depth variation between\\nthe eastern and the western disk.The average depth for the disk is 3.44$\\\\pm$\\n1.16 kpc.In the case of SMC, the bar depth(4.90$\\\\pm$1.23 kpc)and the disk depth\\n(4.23$\\\\pm$1.48kpc)are found to be within the standard deviations.A prominent\\nfeature in the SMC is the increase in depth near the optical center.The large\\ndispersions estimated for the LMC bar and the northern disk suggest that the\\nLMC either has large depth and/or different stellar populations in these\\nregions.The halo of the LMC(using RR Lyrae stars)is found to have larger depth\\ncompared to the disk/bar,which supports the existence of an inner halo for the\\nLMC.On the other hand, the estimated depths for the halo(RR Lyrae stars)and\\ndisk are found to be similar,for the SMC bar region. Thus,increased depth and\\nenhanced stellar as well as HI density near the optical center suggests that\\nthe SMC may have a bulge.\\n')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.doc_store[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_flags = [rag.doc_store[i].metadata['id'] == id_true for i in I[0]]\n",
    "find_index_next(relevant_flags, True, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1770322630410,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "xULG5E8-cixP"
   },
   "outputs": [],
   "source": [
    "k_ranked = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1770322682389,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "CmSG_UDxdEFU",
    "outputId": "7901c471-c3a7-43cc-e0ca-342e711139a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  In this work, we present the first corpus for German Adverse Drug Reaction\\n(ADR) detection in patient-generated content. The data consists of 4,169 binary\\nannotated documents from a German patient forum, where users talk about health\\nissues and get advice from medical doctors. As is common in social media data\\nin this domain, the class labels of the corpus are very imbalanced. This and a\\nhigh topic imbalance make it a very challenging dataset, since often, the same\\nsymptom can have several causes and is not always related to a medication\\nintake. We aim to encourage further multi-lingual efforts in the domain of ADR\\ndetection and provide preliminary experiments for binary classification using\\ndifferent methods of zero- and few-shot learning based on a multi-lingual\\nmodel. When fine-tuning XLM-RoBERTa first on English patient forum data and\\nthen on the new German data, we achieve an F1-score of 37.52 for the positive\\nclass. We make the dataset and models publicly available for the community.\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "error",
     "timestamp": 1770322896604,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "072dIu1dc50f",
    "outputId": "f8597c0a-657c-4f63-b069-7179e0f1957e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/ubuntu/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scores = rag.rerank(q, candidates)\n",
    "array = np.array(scores)\n",
    "indices = np.argsort(array)[::-1][:k_ranked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 4, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 86, 18, 80, 20]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_ids = [int(I[0][i]) for i in indices]\n",
    "ranked_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_flags = [rag.doc_store[i].metadata['id'] == id_true for i in ranked_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_index_next(relevant_flags, True, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/ubuntu/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2714: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "1it [00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=0, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=1, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=2, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:02,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=3, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=4, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:03,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=5, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:04,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=6, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:04,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=7, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:05,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=8, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:05,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=9, relev_index = 1, mrr5_step=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "K_mrr = 5\n",
    "N_cands_rerank = 5\n",
    "\n",
    "mrr5_list = []\n",
    "for j, row in tqdm(df_test[:10].iterrows()):\n",
    "  # print(index, row['id'])\n",
    "  q = row['query']\n",
    "  id_true = row['id']\n",
    "\n",
    "\n",
    "  _, I = rag.search(q, k=N_cands_rerank)\n",
    "  candidates = [rag.doc_store[i].page_content for i in I[0]]\n",
    "  scores = rag.rerank(q, candidates)\n",
    "  array = np.array(scores)\n",
    "  indices = np.argsort(array)[::-1][:K_mrr]\n",
    "  ranked_ids = [int(I[0][i]) for i in indices]\n",
    "\n",
    "  relevant_flags = [rag.doc_store[i].metadata['id'] == id_true for i in ranked_ids]   # i in I[0]]\n",
    "  relev_index = find_index_next(relevant_flags, True, np.inf)\n",
    "\n",
    "  mrr5_step = 1 / relev_index\n",
    "  if mrr5_step > 0 :\n",
    "    print(f'j={j}, relev_index = {relev_index}, mrr5_step={mrr5_step}')\n",
    "  mrr5_list.append(mrr5_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1770320952265,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "1moNxqdUS1kb",
    "outputId": "144ab6d9-41fc-4aa2-85c2-3ddbe88eb841"
   },
   "outputs": [],
   "source": [
    "MRR5 = sum(mrr5_list) / len(mrr5_list)\n",
    "MRR5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1770320952305,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "sXcG7r8jSqMu",
    "outputId": "a6470f1c-29ca-4178-8005-6cb513f4db4f"
   },
   "outputs": [],
   "source": [
    "1 / np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1770318081143,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "EFMGV40ULgdO",
    "outputId": "321741eb-bff4-4337-c160-77b64b0e194b"
   },
   "outputs": [],
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1770319204848,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "1NU1TeDSMBc1",
    "outputId": "5ad0178a-6674-4210-e118-5811ad87a972"
   },
   "outputs": [],
   "source": [
    "relevant_flags = [rag.doc_store[i].metadata['id'] == id_true for i in I[0]]\n",
    "relevant_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1770319608138,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "7xaA5lXWRBhH"
   },
   "outputs": [],
   "source": [
    "relevant_flags = [True, False, False, True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1770319621759,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "DnS4u8J0Q11O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1770319625407,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "MBnRhe3ORKMA",
    "outputId": "92ac5bd3-1d38-42eb-c0be-84210f35d26b"
   },
   "outputs": [],
   "source": [
    "find_index_next(relevant_flags, True, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109,
     "status": "ok",
     "timestamp": 1770319538894,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "uAO0NxF5QwZf",
    "outputId": "efc373ba-755a-4b31-fc7d-28a4e7967270"
   },
   "outputs": [],
   "source": [
    "find_index_or_none_next(relevant_flags, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "error",
     "timestamp": 1770319369297,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "uVbO_PyaQVS4",
    "outputId": "d151c97f-7631-4d91-c050-91ed9f79af4d"
   },
   "outputs": [],
   "source": [
    "relevant_flags.index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25JolnvVP1qx"
   },
   "outputs": [],
   "source": [
    "mrr@5 ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1770319307310,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "BSlPErjtQKxD",
    "outputId": "da021df8-9ceb-4b67-b2a4-0f96c4eaef2c"
   },
   "outputs": [],
   "source": [
    "next((item for item in relevant_flags if item), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1770319176976,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "1V7d-jU6Pryc",
    "outputId": "cb7018f0-cb61-4d23-c716-a9b7cb44b976"
   },
   "outputs": [],
   "source": [
    "[rag.doc_store[i].metadata['id'] for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHoPP_G_Lis2"
   },
   "outputs": [],
   "source": [
    "candidates = [rag.doc_store[i].page_content for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1770318236862,
     "user": {
      "displayName": "Ruslan Ruslan",
      "userId": "15132103594151884603"
     },
     "user_tz": -180
    },
    "id": "rq892e6TLy5E",
    "outputId": "94e7cae6-0a74-420c-b9dd-ab92255d8887"
   },
   "outputs": [],
   "source": [
    "rag.doc_store[23].metadata['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCcqHi-8L0gH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP4tEok5cit2ymCUEuNxYP9",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
